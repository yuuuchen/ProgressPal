# -*- coding: utf-8 -*-
"""0815_ä¸»ç¨‹å¼_ç‰ˆæœ¬ä¸€.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1utsOhc6Rweb0TBKWDRmoM0jeyqp2qNT5
"""

!pip install -U google-genai

from google import genai
from google.genai import types
from google.colab import userdata
from IPython.display import Markdown
import textwrap, os, json, re

def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

def extract_json(text: str):
    """å®¹éŒ¯ï¼šå»æ‰ ``` èˆ‡å¤šé¤˜æ–‡å­—ï¼ŒæŠ“å‡ºæœ€å¤–å±¤ JSON é™£åˆ—"""
    if not text:
        raise ValueError("æ¨¡å‹å›å‚³æ˜¯ç©ºå­—ä¸²")
    t = text.strip()
    if t.startswith("```"):
        t = re.sub(r"^```(?:json)?\s*|\s*```$", "", t, flags=re.DOTALL)
    try:
        return json.loads(t)
    except json.JSONDecodeError:
        m = re.search(r"\[.*\]", t, flags=re.DOTALL)
        if m:
            return json.loads(m.group(0))
        raise

# è¨­å®š API é‡‘é‘°
API_KEY = userdata.get('GOOGLE_API_KEY')
client = genai.Client(api_key=API_KEY)

"""æ•™æåˆ‡åˆ†


"""

# ä¸Šå‚³ PDF
pdf_path = "ä¸²åˆ—.pdf"
assert os.path.exists(pdf_path), f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {pdf_path}"

myfile = client.files.upload(file=pdf_path)
print("å·²ä¸Šå‚³:", myfile.uri)

# Gemini åˆ†æ®µ
split_prompt = """
ä½ æ˜¯ä¸€ä½è³‡æ–™çµæ§‹èª²ç¨‹çš„åŠ©æ•™ã€‚è«‹å°‡é€™ä»½ PDFï¼ˆè¦–ç‚ºåŒä¸€ç« ç¯€ï¼‰åŠƒåˆ†ç‚ºè‹¥å¹²ã€Œå–®å…ƒã€ã€‚
è¦å‰‡ï¼š
- ä¾æ•™æè‡ªç„¶çµæ§‹åˆ‡åˆ†ï¼Œæ¯å–®å…ƒå…§å®¹èˆ‡åç¨±çš†ä¸é‡ç–Šã€‚
- æ¯å€‹å–®å…ƒç”¨ 1 è¡Œã€Œunit_titleã€å‘½åï¼ˆä¸è¶…é 16 å€‹å­—ï¼Œå‹™å¿…æœ‰èªæ„ï¼‰ã€‚
- ã€Œcontentã€ç‚ºè©²å–®å…ƒéœ€æ•™æˆçš„é‡é»æ‘˜è¦ï¼ˆåŒ…å«å®šç¾©/é‡é»æ¸…å–®/èˆ‰ä¾‹ï¼‰ï¼Œé•·åº¦å»ºè­° 300~500 å­—ã€‚
- åƒ…è¼¸å‡º JSONï¼Œå‹¿åŠ ä»»ä½•èªªæ˜æˆ–æ¨™è¨»ã€‚
"""

gen_config = types.GenerateContentConfig(
    response_mime_type="application/json",
    response_schema=types.Schema(
        type=types.Type.ARRAY,
        items=types.Schema(
            type=types.Type.OBJECT,
            properties={
                "unit_title": types.Schema(type=types.Type.STRING),
                "content": types.Schema(type=types.Type.STRING),
            },
            required=["unit_title", "content"],
        ),
    ),
)

split_response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[types.Content(role="user", parts=[
        types.Part(file_data=types.FileData(
            file_uri=myfile.uri,
            mime_type="application/pdf"
        )),
        types.Part(text=split_prompt)
    ])],
    config=gen_config
)

raw_text = split_response.text

try:
    units = json.loads(raw_text)
except json.JSONDecodeError:
    units = extract_json(raw_text)

assert isinstance(units, list) and len(units) > 0, "åˆ†æ®µçµæœç‚ºç©º"
for i, u in enumerate(units, 1):
    print(f"{i:02d}. {u['unit_title']}  (ç´„ {len(u['content'])} å­—)")

"""**å–®å…ƒæ•™å­¸**

ç„¡ç‰¹å®šèªªæ˜æ•™æå‘ˆç¾æ–¹å¼èˆ‡å­¸ç”Ÿç¨‹åº¦(åˆå­¸/è¤‡ç¿’)
"""

# å›ºå®šæ•™å­¸æŒ‡ä»¤
system_instruction = "ä½ æ˜¯ä¸€ä½è³‡æ–™çµæ§‹èª²ç¨‹çš„å®¶æ•™ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡ä»”ç´°åœ°è¬›è§£ä»¥ä¸‹å–®å…ƒå…§å®¹ï¼Œä¸¦é©åº¦èˆ‰ä¾‹(éœ€æä¾›è§£ç­”)ã€‚"

# æ•™å­¸æƒ…ç·’å°æ‡‰è¡¨ï¼ˆå›å‚³ tone å’Œ styleï¼‰
def emotion_instruction_map(emotion):
    mapping = {
        "frustrated": {"tone": "æº«æš–ä¸”å®‰æ’«", "style": "å¾ªåºæ¼¸é€²ã€æ‹†è§£å•é¡Œ"},
        "confused": {"tone": "æº«å’Œä¸”è€å¿ƒ", "style": "èˆ‰ä¾‹å°ç…§ã€æ¯”å–»è§£é‡‹"},
        "bored": {"tone": "æ´»æ½‘ä¸”æœ‰è¶£", "style": "åŠ å…¥æƒ…å¢ƒåŒ–æ¡ˆä¾‹ã€äº’å‹•æå•"},
        "engaged": {"tone": "ç©æ¥µä¸”è‚¯å®š", "style": "æ·±å…¥æ¢è¨ã€å¼•å°å»¶ä¼¸æ€è€ƒ"},
        "surprised": {"tone": "ç†±æƒ…ä¸”é¼“å‹µ", "style": "å»¶ä¼¸è¶£å‘³é»ã€å¼•å…¥æ–°è¦–è§’"},
        "joyful": {"tone": "è¼•é¬†ä¸”æ­£å‘", "style": "èå…¥æŒ‘æˆ°é¡Œã€é¼“å‹µè‡ªæˆ‘æ¢ç´¢"},
    }
    return mapping.get(emotion, {"tone": "ä¸­æ€§", "style": "ä¸€èˆ¬è§£é‡‹"})

conversation_history = ""
last_emotion_profile = {"tone": "ä¸­æ€§", "style": "ä¸€èˆ¬è§£é‡‹"}  # ç¬¬ä¸€å–®å…ƒé è¨­ä¸­æ€§
last_emotion = "ä¸­æ€§"

for idx, unit in enumerate(units, start=1):
    print(f"\n=== å–®å…ƒ {idx}ï¼š{unit['unit_title']} ===\n")

    # æ•™å­¸
    lecture_prompt = (
        system_instruction
        + f"\nä½ æ˜¯ä¸€ä½{last_emotion_profile['tone']}çš„è³‡æ–™çµæ§‹åŠ©æ•™ï¼Œç¾åœ¨é¢å°ä¸€ä½æ„Ÿåˆ°{last_emotion}çš„å­¸ç”Ÿ"
          f"è«‹ç”¨{last_emotion_profile['style']}æ–¹å¼è¬›è§£(ã€‚\n"
        + unit["content"]
    )
    print("ğŸ”¹ æ­£åœ¨ç”Ÿæˆæ•™å­¸å…§å®¹...")
    lecture_resp = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[types.Content(role="user", parts=[
            types.Part(text=lecture_prompt)
        ])]
    )
    lecture_text = lecture_resp.text
    display(to_markdown(lecture_text))

    print("ğŸ”¹ é€²å…¥å•ç­”éšæ®µ")
    # å•ç­”éšæ®µ
    while True:
        q = input("å­¸ç”Ÿæå•æˆ–è¼¸å…¥ next é€²å…¥ä¸‹ä¸€å–®å…ƒï¼š")
        if q.strip().lower() == "next":
            break

        tone = last_emotion_profile.get("tone", "ä¸­æ€§")
        style = last_emotion_profile.get("style", "ä¸€èˆ¬è§£é‡‹")

        answer_prompt = f"""ä½ æ˜¯ä¸€ä½{tone}çš„è³‡æ–™çµæ§‹åŠ©æ•™ã€‚
        è«‹ç”¨{style}æ–¹å¼ï¼Œé¢å°ä¸€ä½æ„Ÿåˆ°{last_emotion}çš„å­¸ç”Ÿï¼Œ
        å›ç­”ä»¥ä¸‹å•é¡Œï¼š{q}
        è«‹æ ¹æ“šä»¥ä¸‹æ•™æå›ç­”ï¼Œé¿å…è¶…å‡ºç¯„åœï¼š
        {unit['content']}
        è‹¥å•é¡Œèˆ‡æ•™æç„¡é—œï¼Œè«‹å›è¦†ã€Œé€™å€‹å•é¡Œèˆ‡æœ¬å–®å…ƒæ•™æç„¡é—œã€ã€‚
        """
        print("ğŸ”¹ æ­£åœ¨ç”Ÿæˆç­”è¦†...")
        ans_resp = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[types.Content(role="user", parts=[
                types.Part(text=answer_prompt)
            ])]
        )
        ans_text = ans_resp.text
        display(to_markdown(ans_text))
        conversation_history += f"\n[å–®å…ƒ{idx}] å•ï¼š{q}\nç­”ï¼š{ans_text}"

    # å•ç­”çµæŸå¾Œï¼Œè¼¸å…¥æ–°çš„æƒ…ç·’ï¼ˆç¬¬äºŒå–®å…ƒé–‹å§‹æ‰æ›´æ–°ï¼‰
    detected_emotion = input("è«‹è¼¸å…¥åµæ¸¬åˆ°çš„å­¸ç”Ÿæƒ…ç·’ï¼š")
    last_emotion_profile = emotion_instruction_map(detected_emotion)
    last_emotion = detected_emotion

"""æœ‰æŒ‡ä»¤-åˆå­¸"""

# å›ºå®šæ•™å­¸æŒ‡ä»¤ï¼šç”±å‡½å¼å‹•æ…‹ç”¢ç”Ÿï¼ˆå¸¶å…¥å­¸ç¿’éšæ®µèˆ‡æ¨¡å¼ï¼‰
def learning_mode(stage):
    mapping = {
        "åˆå­¸": "ç°¡å–®ä¸”ä»”ç´°ã€æ­¥é©Ÿæ‹†è§£ã€ä½¿ç”¨ç”Ÿæ´»åŒ–æ¯”å–»èˆ‡å°ç·´ç¿’",
        "è¤‡ç¿’": "æ·±å…¥ä¸”ç²¾ç…‰ã€å¼·èª¿é‡é»ã€åˆ†ææ™‚é–“èˆ‡ç©ºé–“è¤‡é›œåº¦ã€åˆ—å‡ºå¸¸è¦‹é™·é˜±èˆ‡é‚Šç•Œæ¢ä»¶"
    }
    return mapping.get(stage, "ä¸€èˆ¬è§£èªª")

def build_system_instruction(stage, mode=None):
    mode_text = mode or learning_mode(stage)
    return (
        f"ä½ æ˜¯ä¸€ä½è³‡æ–™çµæ§‹èª²ç¨‹çš„å®¶æ•™ï¼Œç¾åœ¨é¢å°ä¸€ä½{stage}è³‡æ–™çµæ§‹çš„å­¸ç”Ÿï¼Œ"
        f"è«‹ç”¨ç¹é«”ä¸­æ–‡ã€æ¡ç”¨{mode_text}è¬›è§£ä»¥ä¸‹å–®å…ƒå…§å®¹ï¼Œä¸¦é©åº¦èˆ‰ä¾‹ï¼ˆéœ€æä¾›è§£ç­”ï¼‰ã€‚\n"
        "å›æ‡‰çµæ§‹ï¼š\n"
        "1) æ ¸å¿ƒè§€å¿µï¼ˆ3â€“5é»ï¼‰\n"
        "2) è¿·æ€æ¾„æ¸…ï¼ˆ2é»ï¼‰\n"
        "3) ä¾‹é¡Œèˆ‡è©³ç´°è§£ç­”ï¼ˆè‡³å°‘1é¡Œï¼‰\n"
        "4) å°æ¸¬é©—ï¼ˆ2é¡Œï¼Œé™„ç­”æ¡ˆï¼‰"
    )

# æ•™å­¸æƒ…ç·’å°æ‡‰è¡¨ï¼ˆå›å‚³ tone å’Œ styleï¼‰
def emotion_instruction_map(emotion):
    mapping = {
        "frustrated": {"tone": "æº«æš–ä¸”å®‰æ’«", "style": "å¾ªåºæ¼¸é€²ã€æ‹†è§£å•é¡Œ"},
        "confused":   {"tone": "æº«å’Œä¸”è€å¿ƒ", "style": "èˆ‰ä¾‹å°ç…§ã€æ¯”å–»è§£é‡‹"},
        "bored":      {"tone": "æ´»æ½‘ä¸”æœ‰è¶£", "style": "åŠ å…¥æƒ…å¢ƒåŒ–æ¡ˆä¾‹ã€äº’å‹•æå•"},
        "engaged":    {"tone": "ç©æ¥µä¸”è‚¯å®š", "style": "æ·±å…¥æ¢è¨ã€å¼•å°å»¶ä¼¸æ€è€ƒ"},
        "surprised":  {"tone": "ç†±æƒ…ä¸”é¼“å‹µ", "style": "å»¶ä¼¸è¶£å‘³é»ã€å¼•å…¥æ–°è¦–è§’"},
        "joyful":     {"tone": "è¼•é¬†ä¸”æ­£å‘", "style": "èå…¥æŒ‘æˆ°é¡Œã€é¼“å‹µè‡ªæˆ‘æ¢ç´¢"},
    }
    return mapping.get(emotion, {"tone": "ä¸­æ€§", "style": "ä¸€èˆ¬è§£é‡‹"})

# ===== ä¸»æµç¨‹ =====
conversation_history = ""
last_emotion_profile = {"tone": "ä¸­æ€§", "style": "ä¸€èˆ¬è§£é‡‹"}  # ç¬¬ä¸€å–®å…ƒå›ºå®šä¸­æ€§
last_emotion = "ä¸­æ€§"

learning_stage = "åˆå­¸"   # æˆ– "è¤‡ç¿’"

base_system_instruction = build_system_instruction(learning_stage)

for idx, unit in enumerate(units, start=1):
    print(f"\n=== å–®å…ƒ {idx}ï¼š{unit['unit_title']} ===\n")

    # ç¬¬ä¸€å–®å…ƒï¼šä¸­æ€§èªæ°£ï¼›ç¬¬äºŒå–®å…ƒèµ·åŠ å…¥æƒ…ç·’çš„å£å»/é¢¨æ ¼
    emotion_line = "" if idx == 1 else (
        f"ä½ ç¾åœ¨æ‡‰ä»¥{last_emotion_profile['tone']}çš„èªæ°£ï¼Œä¸¦æ¡ç”¨{last_emotion_profile['style']}å‘ˆç¾ã€‚"
    )

    # === å–®å…ƒè¬›è§£ Prompt ===
    lecture_prompt = (
        base_system_instruction + "\n" +
        emotion_line + "\n" +
        "ä»¥ä¸‹æ˜¯æœ¬å–®å…ƒæ•™æï¼Œè«‹æ ¹æ“šæ•™æé€²è¡Œè¬›è§£ï¼Œä¸è¦å›ç­”å…¶ä»–å•é¡Œï¼š\n" +
        unit["content"]
    )

    print("ğŸ”¹ æ­£åœ¨ç”Ÿæˆæ•™å­¸å…§å®¹...")
    lecture_resp = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[types.Content(role="user", parts=[types.Part(text=lecture_prompt)])]
    )
    lecture_text = lecture_resp.text
    display(to_markdown(lecture_text))

    # === å•ç­”éšæ®µ ===
    print("ğŸ”¹ é€²å…¥å•ç­”éšæ®µ")
    while True:
        q = input("å­¸ç”Ÿæå•æˆ–è¼¸å…¥ next é€²å…¥ä¸‹ä¸€å–®å…ƒï¼š")
        if q.strip().lower() == "next":
            break

        tone = last_emotion_profile.get("tone", "ä¸­æ€§")
        style = last_emotion_profile.get("style", "ä¸€èˆ¬è§£é‡‹")

        # === å•é¡Œå›ç­” Promptï¼ˆèˆ‡å–®å…ƒè¬›è§£åˆ†é–‹ï¼‰ ===
        qa_prompt = (
            f"ä½ æ˜¯ä¸€ä½{tone}çš„è³‡æ–™çµæ§‹åŠ©æ•™ï¼Œè«‹ç”¨{style}çš„æ–¹å¼å›ç­”å­¸ç”Ÿå•é¡Œã€‚\n"
            "å›ç­”æ™‚åƒ…èƒ½ä¾æ“šä»¥ä¸‹æ•™æå…§å®¹ä½œç­”ï¼›å¦‚æœå•é¡Œèˆ‡æ•™æç„¡é—œï¼Œè«‹å›ç­”ã€Œé€™å€‹å•é¡Œèˆ‡æœ¬å–®å…ƒæ•™æç„¡é—œã€ã€‚\n"
            f"æ•™æï¼š\n{unit['content']}\n"
            f"å­¸ç”Ÿå•é¡Œï¼š{q}"
        )

        print("ğŸ”¹ æ­£åœ¨ç”Ÿæˆç­”è¦†...")
        ans_resp = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[types.Content(role="user", parts=[types.Part(text=qa_prompt)])]
        )
        ans_text = ans_resp.text
        display(to_markdown(ans_text))
        conversation_history += f"\n[å–®å…ƒ{idx}] å•ï¼š{q}\nç­”ï¼š{ans_text}"

    # å•ç­”çµæŸå¾Œè¼¸å…¥æ–°çš„æƒ…ç·’
    detected_emotion = input("è«‹è¼¸å…¥åµæ¸¬åˆ°çš„å­¸ç”Ÿæƒ…ç·’ï¼š")
    last_emotion_profile = emotion_instruction_map(detected_emotion)
    last_emotion = detected_emotion

"""æœ‰æŒ‡ä»¤-è¤‡ç¿’"""

# å›ºå®šæ•™å­¸æŒ‡ä»¤ï¼šç”±å‡½å¼å‹•æ…‹ç”¢ç”Ÿï¼ˆå¸¶å…¥å­¸ç¿’éšæ®µèˆ‡æ¨¡å¼ï¼‰
def learning_mode(stage):
    mapping = {
        "åˆå­¸": "ç°¡å–®ä¸”ä»”ç´°ã€æ­¥é©Ÿæ‹†è§£ã€ä½¿ç”¨ç”Ÿæ´»åŒ–æ¯”å–»èˆ‡å°ç·´ç¿’",
        "è¤‡ç¿’": "æ·±å…¥ä¸”ç²¾ç…‰ã€å¼·èª¿é‡é»ã€åˆ†ææ™‚é–“èˆ‡ç©ºé–“è¤‡é›œåº¦ã€åˆ—å‡ºå¸¸è¦‹é™·é˜±èˆ‡é‚Šç•Œæ¢ä»¶"
    }
    return mapping.get(stage, "ä¸€èˆ¬è§£èªª")

def build_system_instruction(stage, mode=None):
    mode_text = mode or learning_mode(stage)
    return (
        f"ä½ æ˜¯ä¸€ä½è³‡æ–™çµæ§‹èª²ç¨‹çš„å®¶æ•™ï¼Œç¾åœ¨é¢å°ä¸€ä½{stage}è³‡æ–™çµæ§‹çš„å­¸ç”Ÿï¼Œ"
        f"è«‹ç”¨ç¹é«”ä¸­æ–‡ã€æ¡ç”¨{mode_text}è¬›è§£ä»¥ä¸‹å–®å…ƒå…§å®¹ï¼Œä¸¦é©åº¦èˆ‰ä¾‹ï¼ˆéœ€æä¾›è§£ç­”ï¼‰ã€‚\n"
        "å›æ‡‰çµæ§‹ï¼š\n"
        "1) æ ¸å¿ƒè§€å¿µï¼ˆ3â€“5é»ï¼‰\n"
        "2) è¿·æ€æ¾„æ¸…ï¼ˆ2é»ï¼‰\n"
        "3) ä¾‹é¡Œèˆ‡è©³ç´°è§£ç­”ï¼ˆè‡³å°‘1é¡Œï¼‰\n"
        "4) å°æ¸¬é©—ï¼ˆ2é¡Œï¼Œé™„ç­”æ¡ˆï¼‰"
    )

# æ•™å­¸æƒ…ç·’å°æ‡‰è¡¨ï¼ˆå›å‚³ tone å’Œ styleï¼‰
def emotion_instruction_map(emotion):
    mapping = {
        "frustrated": {"tone": "æº«æš–ä¸”å®‰æ’«", "style": "å¾ªåºæ¼¸é€²ã€æ‹†è§£å•é¡Œ"},
        "confused":   {"tone": "æº«å’Œä¸”è€å¿ƒ", "style": "èˆ‰ä¾‹å°ç…§ã€æ¯”å–»è§£é‡‹"},
        "bored":      {"tone": "æ´»æ½‘ä¸”æœ‰è¶£", "style": "åŠ å…¥æƒ…å¢ƒåŒ–æ¡ˆä¾‹ã€äº’å‹•æå•"},
        "engaged":    {"tone": "ç©æ¥µä¸”è‚¯å®š", "style": "æ·±å…¥æ¢è¨ã€å¼•å°å»¶ä¼¸æ€è€ƒ"},
        "surprised":  {"tone": "ç†±æƒ…ä¸”é¼“å‹µ", "style": "å»¶ä¼¸è¶£å‘³é»ã€å¼•å…¥æ–°è¦–è§’"},
        "joyful":     {"tone": "è¼•é¬†ä¸”æ­£å‘", "style": "èå…¥æŒ‘æˆ°é¡Œã€é¼“å‹µè‡ªæˆ‘æ¢ç´¢"},
    }
    return mapping.get(emotion, {"tone": "ä¸­æ€§", "style": "ä¸€èˆ¬è§£é‡‹"})

# ===== ä¸»æµç¨‹ =====
conversation_history = ""
last_emotion_profile = {"tone": "ä¸­æ€§", "style": "ä¸€èˆ¬è§£é‡‹"}  # ç¬¬ä¸€å–®å…ƒå›ºå®šä¸­æ€§
last_emotion = "ä¸­æ€§"

learning_stage = "è¤‡ç¿’"   # æˆ– "åˆå­¸"

base_system_instruction = build_system_instruction(learning_stage)

for idx, unit in enumerate(units, start=1):
    print(f"\n=== å–®å…ƒ {idx}ï¼š{unit['unit_title']} ===\n")

    # ç¬¬ä¸€å–®å…ƒï¼šä¸­æ€§èªæ°£ï¼›ç¬¬äºŒå–®å…ƒèµ·åŠ å…¥æƒ…ç·’çš„å£å»/é¢¨æ ¼
    emotion_line = "" if idx == 1 else (
        f"ä½ ç¾åœ¨æ‡‰ä»¥{last_emotion_profile['tone']}çš„èªæ°£ï¼Œä¸¦æ¡ç”¨{last_emotion_profile['style']}å‘ˆç¾ã€‚"
    )

    # === å–®å…ƒè¬›è§£ Prompt ===
    lecture_prompt = (
        base_system_instruction + "\n" +
        emotion_line + "\n" +
        "ä»¥ä¸‹æ˜¯æœ¬å–®å…ƒæ•™æï¼Œè«‹æ ¹æ“šæ•™æé€²è¡Œè¬›è§£ï¼Œä¸è¦å›ç­”å…¶ä»–å•é¡Œï¼š\n" +
        unit["content"]
    )

    print("ğŸ”¹ æ­£åœ¨ç”Ÿæˆæ•™å­¸å…§å®¹...")
    lecture_resp = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[types.Content(role="user", parts=[types.Part(text=lecture_prompt)])]
    )
    lecture_text = lecture_resp.text
    display(to_markdown(lecture_text))

    # === å•ç­”éšæ®µ ===
    print("ğŸ”¹ é€²å…¥å•ç­”éšæ®µ")
    while True:
        q = input("å­¸ç”Ÿæå•æˆ–è¼¸å…¥ next é€²å…¥ä¸‹ä¸€å–®å…ƒï¼š")
        if q.strip().lower() == "next":
            break

        tone = last_emotion_profile.get("tone", "ä¸­æ€§")
        style = last_emotion_profile.get("style", "ä¸€èˆ¬è§£é‡‹")

        # === å•é¡Œå›ç­” Promptï¼ˆèˆ‡å–®å…ƒè¬›è§£åˆ†é–‹ï¼‰ ===
        qa_prompt = (
            f"ä½ æ˜¯ä¸€ä½{tone}çš„è³‡æ–™çµæ§‹åŠ©æ•™ï¼Œè«‹ç”¨{style}çš„æ–¹å¼å›ç­”å­¸ç”Ÿå•é¡Œã€‚\n"
            "å›ç­”æ™‚åƒ…èƒ½ä¾æ“šä»¥ä¸‹æ•™æå…§å®¹ä½œç­”ï¼›å¦‚æœå•é¡Œèˆ‡æ•™æç„¡é—œï¼Œè«‹å›ç­”ã€Œé€™å€‹å•é¡Œèˆ‡æœ¬å–®å…ƒæ•™æç„¡é—œã€ã€‚\n"
            f"æ•™æï¼š\n{unit['content']}\n"
            f"å­¸ç”Ÿå•é¡Œï¼š{q}"
        )

        print("ğŸ”¹ æ­£åœ¨ç”Ÿæˆç­”è¦†...")
        ans_resp = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[types.Content(role="user", parts=[types.Part(text=qa_prompt)])]
        )
        ans_text = ans_resp.text
        display(to_markdown(ans_text))
        conversation_history += f"\n[å–®å…ƒ{idx}] å•ï¼š{q}\nç­”ï¼š{ans_text}"

    # å•ç­”çµæŸå¾Œè¼¸å…¥æ–°çš„æƒ…ç·’
    detected_emotion = input("è«‹è¼¸å…¥åµæ¸¬åˆ°çš„å­¸ç”Ÿæƒ…ç·’ï¼š")
    last_emotion_profile = emotion_instruction_map(detected_emotion)
    last_emotion = detected_emotion