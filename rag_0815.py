# -*- coding: utf-8 -*-
"""0815_rag教材模組.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14jAxpxWKDhlFS2xe0hTOhfQiZ7txP5-P
"""

from langchain_community.document_loaders import PyPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from sentence_transformers import SentenceTransformer
from langchain_google_vertexai import ChatVertexAI
from pdf2image import convert_from_path
import pytesseract
from langchain.schema import Document

"""Chunk 切分"""

#載入教材PDF
loader = PyPDFLoader("/content/drive/MyDrive/專題/教材/CH3陣列.pdf")
documents = loader.load()
#切分文字
text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

print(f"共分成 {len(docs)} 段")

for i, chunk in enumerate(docs, 1):
    print(f"段落 {i}:\n{chunk.page_content}\n{'-'*50}")

"""Embeddings"""

#將文本轉成向量
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

"""用Chroma建立向量庫"""

vectorstore = Chroma.from_documents(docs, embeddings, persist_directory="/content/drive/MyDrive/專題/程式碼專區/chroma_db")
vectorstore.persist()

"""將使用者問題轉成向量，找教材裡最相似的幾段內容

Chroma
"""

def retrieve_docs(query, top_k):
  #載入Embeddings和Chroma向量庫
  embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
  vectorstore = Chroma(persist_directory="/content/drive/MyDrive/專題/程式碼專區/chroma_db", embedding_function=embeddings)

  results = vectorstore.similarity_search_with_score(query, k=top_k)
  related_texts = []

  for doc, score in results:
    if score <= 1:
      related_texts.append((doc.page_content))

  return related_texts #回傳成一個list

"""測試"""

query = "二維陣列是什麼?"
related_docs = retrieve_docs(query, top_k=5)

print("找到的相關教材段落：")
for i, doc in enumerate(related_docs, 1):
  print(f"{i}. {doc}\n")

"""Chroma + BM25 混合搜尋"""


from rank_bm25 import BM25Okapi
from sklearn.preprocessing import MinMaxScaler
import numpy as np

def hybrid_search(query, k_vector=20, top_k=5, weight_vector=0.7, weight_bm25=0.3):
    #載入Embeddings和Chroma向量庫
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = Chroma(persist_directory="/content/drive/MyDrive/專題/程式碼專區/chroma_db", embedding_function=embeddings)

    #向量檢索
    vector_results = vectorstore.similarity_search_with_score(query, k=k_vector)

    if not vector_results:
        return []

    #準備BM25資料
    docs_text = [doc.page_content for doc, _ in vector_results]
    bm25 = BM25Okapi([t.split() for t in docs_text])
    bm25_scores = bm25.get_scores(query.split())

    #向量分數（距離轉為相似度1 - score）
    vector_scores = np.array([1 - score for _, score in vector_results])

    #標準化分數
    scaler = MinMaxScaler()
    vector_scores_norm = scaler.fit_transform(vector_scores.reshape(-1, 1)).flatten()
    bm25_scores_norm = scaler.fit_transform(np.array(bm25_scores).reshape(-1, 1)).flatten()

    #加權融合
    final_scores = weight_vector * vector_scores_norm + weight_bm25 * bm25_scores_norm

    #根據融合分數排序
    sorted_pairs = sorted(zip(final_scores, docs_text), key=lambda x: x[0], reverse=True)

    #放進list
    sorted_results = [text for _, text in sorted_pairs]

    #回傳前top_k筆的list
    return sorted_results[:top_k]

"""測試"""

query = "二維陣列是什麼?"
related_docs = hybrid_search(query, k_vector=20, top_k=5)

print("找到的相關教材段落：")
for i, doc in enumerate(related_docs, 1):
  print(f"{i}. {doc}\n")
